{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project - API\n",
    "###### Author: Ashley Jiangyang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "API_KEY = '5PcSbNzoasAV27shj1kJ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Quandl API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "url =  \"https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json?start_date=2017-11-21&end_date=2017-11-21&api_key={}\".format(API_KEY)\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_data': {'limit': None, 'transform': None, 'column_index': None, 'column_names': ['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover'], 'start_date': '2017-11-21', 'end_date': '2017-11-21', 'frequency': 'daily', 'data': [['2017-11-21', 47.25, 48.59, 46.78, 48.39, None, 78502.0, 3782098.0, None, None, None]], 'collapse': None, 'order': None}}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through the tasks for this mini project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colloect the whole year 2017 data\n",
    "url_2017 =  \"https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json?start_date=2017-01-01&end_date=2017-12-31&api_key={}\".format(API_KEY)\n",
    "r_2017 = requests.get(url_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Assigne to 'FSE_2017' and print the object type\n",
    "FSE_2017 = r_2017.json()\n",
    "print(type(FSE_2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest opening price for the stock in this period: 53.11\n",
      "The lowest opening price for the stock in this period: 34.0\n"
     ]
    }
   ],
   "source": [
    "# Assign the first day's open price as the highest and lowest value\n",
    "high, low = FSE_2017['dataset_data']['data'][0][1], FSE_2017['dataset_data']['data'][0][1]\n",
    "\n",
    "# Loop over the entire dataset, keep replacing the highest and lowest value if the loop find one\n",
    "for item in FSE_2017['dataset_data']['data']:\n",
    "    if item[1] == None:\n",
    "        continue\n",
    "    elif item[1] > high:\n",
    "        high = item[1]\n",
    "    if item[1] == None:\n",
    "        continue\n",
    "    elif item[1] < low:\n",
    "        low = item[1]\n",
    "\n",
    "\n",
    "#Print the final value\n",
    "print(\"The highest opening price for the stock in this period: {}\".format(high),\n",
    "      \"The lowest opening price for the stock in this period: {}\".format(low), \n",
    "      sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the largest change in any one day: 2.81\n"
     ]
    }
   ],
   "source": [
    "# Intinal the greatest change as the high - low price as of the first day\n",
    "max_change = FSE_2017['dataset_data']['data'][0][2] - FSE_2017['dataset_data']['data'][0][3]\n",
    "\n",
    "# Replacing the value of greatest change if the for loop finds one\n",
    "for item in FSE_2017['dataset_data']['data']:\n",
    "    if item[2] == None or item[3] == None:\n",
    "        continue\n",
    "    elif item[2] - item[3] > max_change:\n",
    "        max_change = item[2] - item[3]\n",
    "\n",
    "#Print the final value\n",
    "print('the largest change in any one day: {:.3}'.format(max_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days: 3.15\n"
     ]
    }
   ],
   "source": [
    "# use zip to map the value of every other day and get differences between every two other days\n",
    "closing_diff = []\n",
    "for x, y in zip(FSE_2017['dataset_data'][\"data\"][0::], FSE_2017['dataset_data'][\"data\"][2::]):\n",
    "    if y[4] == None or x[4] == None:\n",
    "        continue\n",
    "    closing_diff.append(abs(y[4]-x[4]))\n",
    "max_closing_diff = max(closing_diff)\n",
    "\n",
    "#print the max value\n",
    "print('The largest change between any two days: {:.3}'.format(max_closing_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume dring this year: 89124.34\n"
     ]
    }
   ],
   "source": [
    "# use for loop to count all the records and accumulate the Volume\n",
    "count, total = 0, 0\n",
    "for item in FSE_2017['dataset_data']['data']:    \n",
    "    if item[6] == None:\n",
    "        continue\n",
    "    count += 1\n",
    "    total += item[6]\n",
    "    \n",
    "average = total/count\n",
    "total\n",
    "count\n",
    "#print the average value\n",
    "print('The average daily trading volume dring this year: {}'.format(round(average,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume during this year: 76286.0\n"
     ]
    }
   ],
   "source": [
    "#Use list comprehension and 'sort()' to create the list for volume of the year\n",
    "volume=[item[6] for item in FSE_2017['dataset_data']['data'] if item[6] != None]\n",
    "volume.sort()\n",
    "\n",
    "# Define a function to get the median\n",
    "def findMedian(volume):    \n",
    "    median = float(len(volume))/2\n",
    "    if median % 2 != 0:\n",
    "        return volume[int(median - 0.5)]\n",
    "    else:\n",
    "        return (volume[int(median)] + volume[int(median - 1)])/2   \n",
    "    \n",
    "# Print the calculated median\n",
    "print('The median trading volume during this year: {}'.format(findMedian(volume)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
